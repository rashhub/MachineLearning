{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "We will implement a GAN and run it on face data.\n",
    "\n",
    "Once you are satisfied with your implementation, send hw2.ipynb to **vjojic+comp790+hw3@cs.unc.edu**.\n",
    "\n",
    "Save your python notebook frequently.\n",
    "\n",
    "The deadline for this homework assignment is 4/18/2017 23:59PM EST.\n",
    "\n",
    "$ %These are LaTeX definitions used below to save space\n",
    "\\newcommand{\\zz}{\\mathbf{z}} \\newcommand{\\xx}{\\mathbf{x}} \n",
    "\\newcommand{\\WW}{\\mathbf{W}} \\newcommand{\\rr}{\\mathbf{r}} \n",
    "\\newcommand{\\hh}{\\mathbf{h}} \\newcommand{\\bb}{\\mathbf{b}}\n",
    "\\newcommand{\\dec}{\\textrm{dec}} \\newcommand{\\enc}{\\textrm{enc}} \n",
    "\\newcommand{\\rec}{\\textrm{rec}}\n",
    "\\newcommand{\\relu}{\\textrm{ReLU}} \\newcommand{\\mmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\ssigma}{\\boldsymbol{\\sigma}} \\newcommand{\\eepsilon}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}} \n",
    "\\newcommand{\\argmin}{\\mathop{\\textrm{argmin}}} \n",
    "\\newcommand{\\KL}{\\textrm{KL}}\n",
    "\\newcommand{\\II}{\\mathbf{I}}\n",
    "\\newcommand{\\CC}{\\mathbf{C}}\n",
    "\\newcommand{\\DD}{\\mathbf{D}}\n",
    "\\newcommand{\\conv}{\\textrm{conv}}\n",
    "\\newcommand{\\deconv}{\\textrm{trconv}}\n",
    "\\newcommand{\\ss}{\\mathbf{s}}\n",
    "\\newcommand\\norm[1]{\\left\\lVert#1\\right\\rVert}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\gof\\cutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[1;32mfrom\u001b[0m \u001b[0mcutils_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcutils_ext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: DLL load failed: The specified procedure could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\gof\\cutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[1;31m# and when we receive the lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[1;32mfrom\u001b[0m \u001b[0mcutils_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcutils_ext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: DLL load failed: The specified procedure could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8c434c6c401f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprinting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m from theano.scan_module import (scan, map, reduce, foldl, foldr, clone,\n\u001b[0m\u001b[1;32m     81\u001b[0m                                 scan_checkpoints)\n\u001b[1;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\scan_module\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0m__contact__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Razvan Pascanu <r.pascanu@gmail>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_opt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_checkpoints\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_checkpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\scan_module\\scan_opt.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_scalar_constant_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAlloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAllocEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\tensor\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_other\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m from theano.tensor.var import (\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\tensor\\subtensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcxx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcutils\u001b[0m  \u001b[1;31m# needed to import cutils_ext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mcutils_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcutils_ext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minplace_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\gof\\cutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mcompile_cutils\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[1;32mfrom\u001b[0m \u001b[0mcutils_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcutils_ext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\gof\\cutils.py\u001b[0m in \u001b[0;36mcompile_cutils\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGCC_compiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarch_flags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     cmodule.GCC_compiler.compile_str('cutils_ext', code, location=loc,\n\u001b[0;32m--> 285\u001b[0;31m                                      preargs=args)\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\gof\\cmodule.py\u001b[0m in \u001b[0;36mcompile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[1;32m   2323\u001b[0m             \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__init__.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mdlimport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Rash\\Anaconda3\\lib\\site-packages\\theano\\gof\\cmodule.py\u001b[0m in \u001b[0;36mdlimport\u001b[0;34m(fullpath, suffix)\u001b[0m\n\u001b[1;32m    300\u001b[0m             warnings.filterwarnings(\"ignore\",\n\u001b[1;32m    301\u001b[0m                                     message=\"numpy.ndarray size changed\")\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mimport_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: DLL load failed: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import theano\n",
    "theano.config.optimization=None\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from skimage.filters import gabor_kernel\n",
    "from helpers import *\n",
    "\n",
    "images,_ = load_mnist()\n",
    "\n",
    "def gabor_patch(d,lam, theta, sigma, phase): \n",
    "    x = (np.linspace(1,d,d)/d)-0.5\n",
    "    freq = d / lam\n",
    "    phase = phase*2*np.pi\n",
    "    xs, ys = np.meshgrid(x, x)\n",
    "    theta = (theta/360)*2*np.pi\n",
    "    xr = xs * np.cos(theta)\n",
    "    yr = ys * np.sin(theta)\n",
    "    mask = np.sin(((xr+yr)*freq*2*np.pi)+phase)\n",
    "    gauss = np.exp(-1/(2*(sigma/d)**2)*((xs ** 2) + (ys ** 2)))\n",
    "    \n",
    "    return mask*gauss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Convolution and 2D deconvolution\n",
    "\n",
    "Convolution of an image $\\xx$ with a filter $\\rr$ \n",
    "$$\n",
    "\\conv(\\xx,\\rr)\n",
    "$$\n",
    "is a linear operation. Even though the formulation with the moving windows might seem complicated we can view convolution as computing\n",
    "$$\n",
    "\\conv(\\xx,\\rr) = \\bbeta = \\xx\\WW.\n",
    "$$\n",
    "The important characteristic that distinguishes convolution from other linear operations is the structure of $\\WW$. It reuses the same parameters, and it is mostly sparse. For 2D convolution given a filter $\\rr$ of dimensions $f \\times f$ applied to an image of size $d \\times d$ the matrix $\\WW$ will be of size $(d*d) \\times (d-f+1)*(d-f+1)$ and non-zero entries will be given by\n",
    "$$\n",
    "w_{i*d+j, (i+k)*d+j+l} = r_{k,l}\n",
    "$$\n",
    "where $i,j \\in \\{1,..,d\\}$ and $k,l \\in \\{1,..,f\\}$.\n",
    "\n",
    "\n",
    "In practice we do not construct this matrix explicitly -- there are more efficient ways to compute convolution. However, it is easier to understand the process of deconvolution by looking at the above formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = images[1,:,:]/255\n",
    "img = img - np.mean(img.flatten())\n",
    "img = img/np.sqrt(np.sum(img.flatten()**2.0))\n",
    "\n",
    "f = 9\n",
    "d = img.shape[0]\n",
    "r = gabor_patch(f,0.1,1/4*np.pi,1.5,0.01) + 0.01\n",
    "\n",
    "# really slow\n",
    "W = np.zeros([d*d,(d-f+1)*(d-f+1)])\n",
    "for i in range(d-f+1):\n",
    "    for j in range(d-f+1):\n",
    "        for k in range(f):\n",
    "            for l in range(f):\n",
    "                W[(i+k)*d+j+l,i*(d-f+1)+j] = r[k,l]\n",
    "        \n",
    "beta_really_slow = np.dot(img.flatten(),W).reshape((d-f+1,d-f+1))\n",
    "                \n",
    "# slow\n",
    "beta_slow = np.zeros((d-f+1,d-f+1))\n",
    "for i in range(d-f+1):\n",
    "    for j in range(d-f+1):\n",
    "        patch = img[i:i+f,j:j+f]\n",
    "        beta_slow[i,j] = np.dot(patch.flatten(),r.flatten())\n",
    "\n",
    "# fast\n",
    "beta = scipy.signal.convolve2d(img,np.flipud(np.fliplr(r)),mode='valid')\n",
    "pyplot.figure(figsize=(5,20))\n",
    "\n",
    "pyplot.subplot(1,3,1)\n",
    "gray_plot(img,new_figure=False)\n",
    "pyplot.title('Image')\n",
    "\n",
    "pyplot.subplot(1,3,2)\n",
    "gray_plot(r,new_figure=False)\n",
    "pyplot.title('Filter')\n",
    "\n",
    "pyplot.subplot(1,3,3)\n",
    "gray_plot(beta,new_figure=False)\n",
    "pyplot.title('Response')\n",
    "np.sum((beta - beta_slow)**2.0),np.sum((beta - beta_really_slow)**2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolution\n",
    "\n",
    "**Problem 1 (1pt)** Deconvolution can be seen as an operation of reconstructing the input, $\\xx$, to convolution  given the response $\\bbeta$ and filter $\\WW$\n",
    "$$\n",
    "\\hat{\\xx} = \\argmin_{\\xx} \\frac{1}{2}\\norm{\\xx\\WW - \\bbeta}^2 \n",
    "$$\n",
    "In effect, find $\\hat{\\xx}$ such that its convolution with the filter matches $\\bbeta$.\n",
    "Since the size of $\\xx$ is typically larger than $\\bbeta$ there are many possible solutions and we need to regularize\n",
    "$$\n",
    "\\hat{\\xx} = \\argmin_{\\xx} \\frac{1}{2}\\norm{\\xx\\WW - \\bbeta}^2  + \\frac{\\lambda}{2}\\norm{\\xx}^2\n",
    "$$\n",
    "Closed form solution is\n",
    "$$\n",
    "\\hat{\\xx} = \\beta\\DD\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\DD = ...\n",
    "$$\n",
    "\n",
    "To check your answer assume that \n",
    "$$\\begin{array}{rcrcll}\n",
    "\\textrm{variable} && \\textrm{rows} && \\textrm{columns} & \\\\\n",
    "\\hline\n",
    "\\xx &:& d*d &\\times& 1 &\\textrm{(a vector)}\\\\\n",
    "\\WW &:& (d*d) &\\times& ((d-f+1)*(d-f+1))& \\textrm{(a matrix)}\\\\\n",
    "\\bbeta&:& ((d-f+1)*(d-f+1)) &\\times& 1 &\\textrm{(a vector)},\n",
    "\\end{array}\n",
    "$$ where we note that $m \\times n$ indicates a matrix with $m$ rows and $n$ columns. Hence $\\WW$ has $(d*d)$ rows and $ (d-f+1)*(d-f+1)$ columns. Using these sizes and rules of matrix vector multiplication ensure that $\\hat{\\xx}$ has the size of $ d*d \\times 1$\n",
    "\n",
    "**Hint**: you will find that solution is of form\n",
    "$$\n",
    "\\DD = \\WW^T\\CC\n",
    "$$ where $\\CC$ is another matrix.\n",
    "\n",
    "**Note 1**: the matrix $\\DD$ you derived above is also known as pseudo-inverse of $\\WW$.\n",
    "\n",
    "**Note 2**: the reconstruction will not be exactly the same as the original image. After all we used only one filter which detected changes in intensity from black to white going upward. If you did this correctly you should see error of about 0.2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2 (1pt)** Implement solution for $\\hat{\\xx}$ from ```beta``` and matrix ```W``` we computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recon = np.zeros(img.shape)\n",
    "count = np.zeros(img.shape)\n",
    "\n",
    "C = np.linalg.inv(....)\n",
    "dW = np.dot(W.transpose(),C)\n",
    "recon = np.dot(beta.flatten(),dW)\n",
    "recon = recon.reshape(28,28)\n",
    "pyplot.figure(figsize=(5,20))\n",
    "pyplot.subplot(1,3,1)\n",
    "gray_plot(img,new_figure=False)\n",
    "pyplot.title('Original image')\n",
    "\n",
    "pyplot.subplot(1,3,2)\n",
    "gray_plot(recon,new_figure=False)\n",
    "pyplot.title('Reconstruction')\n",
    "\n",
    "pyplot.subplot(1,3,3)\n",
    "gray_plot(img - recon,new_figure=False)\n",
    "pyplot.title('Error')\n",
    "print('image norm:',np.sum(img**2.0),'Reconstruction norm:',np.sum(recon**2.0),'Error norm:',np.sum((img - recon)**2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Convolution can be expressed as matrix multiplication\n",
    "$$\n",
    "\\conv(\\xx,\\rr) = \\bbeta = \\xx\\WW\n",
    "$$\n",
    "where $\\WW$ can be obtained from filter $\\rr$.\n",
    "\n",
    "Deconvolution operation cannot be expressed as multiplication by\n",
    "a matrix obtained from a filter. Consequently, deconvolution is not equivalent to convolution by another filter.\n",
    "\n",
    "One way to understand this intuitively is to consider what the convolution and deconvolution do at a single offset:\n",
    "* convolution summarizes a patch at the offset into a single value in response \n",
    "* deconvolution takes a single value at the offest in response and recreates a patch.\n",
    "\n",
    "Further the actual computation of matrix $\\DD$ requires matrix inversion which will couple different entries in $\\DD$ and remove parameter regularity and sparsity characteristic of matrix $\\WW$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transposed convolution\n",
    "Rather than implementing deconvolution exactly, we can imagine a situation in which\n",
    "we can approximate the deconvolution matrix by\n",
    "$$\n",
    "\\DD \\approx \\WW^T\\II  = \\WW^T.\n",
    "$$\n",
    "\n",
    "$\\WW^T$ matches the dimensionality of the true matrix $\\DD$. Note that $\\WW^T$ is not a matrix representation of  a filter -- transposition ruins that.\n",
    "\n",
    "However, this type of object -- transpose of a matrix representation of a filter --  can be computed as a gradient of convolutional operation\n",
    "$$\n",
    "\\WW^T = \\nabla_{\\xx} \\conv(\\xx,\\ss) = \\nabla_{\\xx} \\xx\\WW\n",
    "$$\n",
    "Thus, we can express our approximate deconvolution operation -- transposed convolution -- as\n",
    "$$\n",
    "\\deconv(\\bbeta,\\ss) = \\bbeta\\nabla_{\\xx}\\conv(\\xx,\\ss).\n",
    "$$\n",
    "This operation is called transposed convolution. \n",
    "\n",
    "We could optimize filter $\\ss$ such that deconvolved image is close to original\n",
    "$$\n",
    "\\frac{1}{2}\\norm{\\xx - \\deconv(\\conv(\\xx,\\rr),\\ss)}^2\n",
    "$$\n",
    "Accuracy of the reconstruction will depend on \n",
    "* filter $\\rr$'s structure -- even with exact deconvolution the image may not be exactly reconstructable  \n",
    "* accuracy of our assumption that transposed convolution for some filter $\\ss$ is close enough to deconvolution for $\\rr$\n",
    "\n",
    "**Problem 3 (0.5pt)** Complete the code below by implementing the reconstruction cost and computing the gradients using theano. Hint: Reconstruction error should be around 0.35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.signal.conv as conv\n",
    "import theano.tensor.nnet.abstract_conv as abstract_conv\n",
    "\n",
    "def make_shared(name,value):\n",
    "    if type(value) is np.ndarray:\n",
    "        value = value.astype('float32')\n",
    "    else:\n",
    "        value = np.float32(value)\n",
    "    return theano.shared(name=name,value=value)\n",
    "\n",
    "def trconv(output, filters, output_shape, filter_size, subsample=(1, 1), border_mode=(0, 0)):\n",
    "    f1, f2 = (filter_size[0], filter_size[1])\n",
    "    a1 = 1\n",
    "    a2 = 1\n",
    "    o_prime1 = subsample[0] * (output_shape[2] - 1) + a1 + f1 - 2 * border_mode[0]\n",
    "    o_prime2 = subsample[1] * (output_shape[3] - 1) + a2 + f2 - 2 * border_mode[1]\n",
    "    input_shape = (None, None, o_prime1, o_prime2)\n",
    "    input = abstract_conv.conv2d_grad_wrt_inputs(\n",
    "        output, filters, input_shape=input_shape, filter_shape=None,\n",
    "        subsample=subsample, border_mode=border_mode)\n",
    "    return input\n",
    "\n",
    "\n",
    "img4 = img.astype('float32').reshape(1,1,d,d)\n",
    "xv = T.dtensor4('x')\n",
    "xv = xv.astype('float32')\n",
    "r4 = r.reshape(1,1,f,f)\n",
    "rv = make_shared('r',value=r4)\n",
    "hv = T.nnet.conv2d(xv,rv, input_shape = img4.shape, filter_shape = r4.shape,\n",
    "                   filter_flip=False,border_mode=(0,0))\n",
    "\n",
    "# tranposed convolution computed via gradient of\n",
    "# convolution\n",
    "# this operation creates a reconstruction, y, \n",
    "# from filter responses in hv.\n",
    "sv = make_shared('s',value=r.reshape((1,1,f,f)))\n",
    "print(img4.shape)\n",
    "print(r4.shape)\n",
    "#y = deconv(hv,sv,input_shape=img4.shape,filter_shape=r4.shape)\n",
    "y = trconv(hv,sv,output_shape=(None,None,d-f,d-f),filter_size=(f,f))\n",
    "recon_cost = T.mean(...) \n",
    "weight_decay =  0.1*T.mean(sv.flatten()**2.0)\n",
    "cost = recon_cost + weight_decay\n",
    "gsv = ...\n",
    "train = theano.function(inputs=[xv],outputs=cost,updates=[(sv,sv-gsv)])\n",
    "\n",
    "for it in range(1000):\n",
    "    train(img4)\n",
    "    \n",
    "pyplot.figure(figsize=(5,20))    \n",
    "yrecon = y.eval({xv:img4}).reshape((d,d))\n",
    "pyplot.subplot(1,3,1)\n",
    "gray_plot(img,new_figure=False)\n",
    "pyplot.title('Original image')\n",
    "\n",
    "pyplot.subplot(1,3,2)\n",
    "gray_plot(yrecon,new_figure=False)\n",
    "pyplot.title('Reconstruction')\n",
    "\n",
    "pyplot.subplot(1,3,3)\n",
    "gray_plot(img - yrecon,new_figure=False)\n",
    "pyplot.title('Error')\n",
    "print('image norm:',np.sum(img**2.0),'Error norm:',np.sum((img - yrecon)**2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a generative deconvolution network\n",
    "\n",
    "We saw how a digit can be reconstructed from filter responses, either using a exact deconvolution or transposed convolution. Transposed convolution is computationally easier.\n",
    "\n",
    "We can imagine a generative model that generates filter responses and from those responses using a deconvolution generates an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4 (1pt)** Implement generator by plugging in the hidden variables and weights. Hint: if the sizes mismatched, theano will complain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(Z, w,  w2, w3, wx):\n",
    "    h = relu(batchnorm(...))\n",
    "    h2 = relu(batchnorm(...))\n",
    "    h2 = h2.reshape((h2.shape[0], ngf*2, 7, 7))\n",
    "    h3 = relu(batchnorm(trconv(..., ..., output_shape=(None,None,7,7),filter_size=(5,5),subsample=(2, 2), border_mode=(2, 2))))\n",
    "    x = sigmoid(trconv(..., ..., output_shape=(None, None, 14, 14),\n",
    "                                   filter_size=(5, 5), subsample=(2, 2), border_mode=(2, 2)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5 (1pt)** Implement discriminator by plugging in the hidden variables and weights. Hint: if the sizes mismatched, theano will complain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discrim(X, w, w2, w3, wy):    \n",
    "    h = relu(conv2d(... subsample=(2, 2), border_mode=(2, 2)),alpha=0.2)\n",
    "    h2 = relu(batchnorm(conv2d(... subsample=(2, 2), border_mode=(2, 2))),alpha=0.2)\n",
    "    h2 = T.flatten(h2, 2)    \n",
    "    h3 = relu(batchnorm(T.dot(...)),alpha=0.2)\n",
    "    y = sigmoid(T.dot(...))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 6 (1pt)** Implement cost for discriminator and generator of the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k = 1             # # of discrim updates for each gen update\n",
    "l2 = 2.5e-5       # l2 weight decay\n",
    "b1 = 0.5          # momentum term of adam\n",
    "nc = 1            # # of channels in image\n",
    "nbatch = 128      # # of examples in batch\n",
    "npx = 28          # # of pixels width/height of images\n",
    "nz = 100          # # of dim for Z\n",
    "ngfc = 1024       # # of gen units for fully connected layers\n",
    "ndfc = 1024       # # of discrim units for fully connected layers\n",
    "ngf = 64          # # of gen filters in first conv layer\n",
    "ndf = 64          # # of discrim filters in first conv layer\n",
    "nx = npx*npx*nc   # # of dimensions in X\n",
    "niter = 100       # # of iter at starting learning rate\n",
    "niter_decay = 100 # # of iter to linearly decay learning rate to zero\n",
    "lr = 0.0002       # initial learning rate for adam\n",
    "\n",
    "\n",
    "gw  = make_shared('gw',0.02*np.random.randn(nz, ngfc))\n",
    "gw2 = make_shared('gw2',0.02*np.random.randn(ngfc, ngf*2*7*7) )\n",
    "gw3 = make_shared('gw3',0.02*np.random.randn(ngf*2, ngf, 5, 5) )\n",
    "gwx = make_shared('gwx',0.02*np.random.randn(ngf, nc, 5, 5) )\n",
    "\n",
    "dw  = make_shared('dw',0.02*np.random.randn(ndf, nc, 5, 5))\n",
    "dw2 = make_shared('dw2',0.02*np.random.randn(ndf*2, ndf, 5, 5))\n",
    "dw3 = make_shared('dw3',0.02*np.random.randn(ndf*2*7*7, ndfc))\n",
    "dwy = make_shared('dwy',0.02*np.random.randn(ndfc, 1))\n",
    "\n",
    "gen_params = [gw, gw2, gw3, gwx]\n",
    "discrim_params = [dw, dw2, dw3, dwy ]\n",
    "X = T.tensor4()\n",
    "Z = T.matrix()\n",
    "\n",
    "gX = gen(Z, *gen_params)\n",
    "\n",
    "p_real = discrim(X, *discrim_params)\n",
    "p_gen = discrim(gX, *discrim_params)\n",
    "\n",
    "g_cost = (...).mean()\n",
    "d_cost = (...).mean() + (....).mean()\n",
    "\n",
    "for p in discrim_params:\n",
    "    d_wd = T.sum(p.flatten()**2.0)\n",
    "\n",
    "for p in gen_params:\n",
    "    g_wd = T.sum(p.flatten()**2.0)\n",
    "    \n",
    "cost = [g_cost, d_cost]\n",
    "\n",
    "lrt = make_shared('lrt',lr)\n",
    "d_updates = adam(d_cost+l2/2*d_wd,discrim_params,beta1=b1,learning_rate=lrt)\n",
    "g_updates = adam(g_cost+l2/2*g_wd,gen_params,beta1=b1,learning_rate=lrt)\n",
    "updates = d_updates + g_updates\n",
    "\n",
    "t = time()\n",
    "train_g = theano.function([X, Z], cost, updates=g_updates)\n",
    "train_d = theano.function([X, Z], cost, updates=d_updates)\n",
    "gen = theano.function([Z], gX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Problem 7 (0.5pt)** Run your code.Every 5 iterations the code will show an image of 200 generated digits.\n",
    " If the generated images in later epochs look like digits then you are successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n_updates = 0\n",
    "ntrain = images.shape[0]\n",
    "\n",
    "vis_zbatch = np.float32(np_rng.uniform(-1., 1., size=(100, nz)))\n",
    "\n",
    "for epoch in range(1, niter+niter_decay+1):\n",
    "    images = shuffle(images)\n",
    "    for i in range(0,ntrain,ntrain//nbatch):\n",
    "        im_batch = transform(images[i:i+nbatch].reshape(-1,1,28,28))\n",
    "        z_batch = np.float32(np_rng.uniform(-1., 1., size=(len(im_batch), nz)))\n",
    "        if n_updates % (k+1) == 0:\n",
    "            cost = train_g(im_batch, z_batch)\n",
    "        else:\n",
    "            cost = train_d(im_batch, z_batch)\n",
    "        n_updates += 1\n",
    "        \n",
    "    samples = np.asarray(gen(vis_zbatch))\n",
    "    \n",
    "    if (epoch-1) % 5 == 0:        \n",
    "        g_cost = float(cost[0])\n",
    "        d_cost = float(cost[1])\n",
    "        print(epoch,g_cost,d_cost,np.abs(samples[0]).mean())\n",
    "        show_examples(samples.squeeze(),h=28,w=28)\n",
    "        pyplot.title('Epoch ' + str(epoch))\n",
    "            \n",
    "    if epoch > niter:\n",
    "        lrt.set_value(np.float32(lrt.get_value() - lr/niter_decay))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
